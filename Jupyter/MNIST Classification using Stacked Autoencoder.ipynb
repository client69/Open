{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18BCE143_practical_6_stacked_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qvX-8VBN-JG"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.layers import Conv2D,Dense,MaxPooling2D,Flatten,Input\n",
        "from tensorflow.keras import Model,Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.image import rgb_to_grayscale\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6sHGm89OHZ3",
        "outputId": "c705b865-ebd6-48e5-e493-9e7e18a283fc"
      },
      "source": [
        "(X_train,y_train),(X_test,y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY5DvZs0OLnH",
        "outputId": "42cdd02d-6f33-4d86-d68e-d729f343bbad"
      },
      "source": [
        "print(\"Number of image in train set :-\",X_train.shape[0])\n",
        "print(\"Number of image in test set :-\",X_test.shape[0])\n",
        "print(\"Resolution of image :-\",X_train.shape[1],'*',X_train.shape[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of image in train set :- 60000\n",
            "Number of image in test set :- 10000\n",
            "Resolution of image :- 28 * 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmll3KW9OXnQ"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAHL0eAIOcZm"
      },
      "source": [
        "X_train = X_train.astype('float32').reshape((X_train.shape[0], 784))\n",
        "X_test = X_test.astype('float32').reshape((X_test.shape[0], 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9owPa3ROTnQ"
      },
      "source": [
        "input_img = Input(shape=(784,))\n",
        "layer_1 = Dense(100,activation='relu')(input_img)\n",
        "layer_2 = Dense(10,activation='relu')(layer_1)\n",
        "layer_3 = Dense(100,activation='relu')(layer_2)\n",
        "output = Dense(784,activation='relu')(layer_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEE4kD8DQNMv",
        "outputId": "86932329-9a12-4a99-8e8d-cf146ffdbb6a"
      },
      "source": [
        "model = Model(inputs=input_img,outputs=output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               1100      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 784)               79184     \n",
            "=================================================================\n",
            "Total params: 159,794\n",
            "Trainable params: 159,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeLY2vrAQbDr"
      },
      "source": [
        "model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W947hxCQkKN",
        "outputId": "dd3860b6-aea1-4f86-aecf-04342c06afc0"
      },
      "source": [
        "history = model.fit(X_train,X_train,epochs=150,batch_size=32,validation_data=(X_test,X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1875/1875 [==============================] - 7s 2ms/step - loss: 0.0407 - accuracy: 0.0097 - val_loss: 0.0275 - val_accuracy: 0.0096\n",
            "Epoch 2/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0273 - accuracy: 0.0092 - val_loss: 0.0257 - val_accuracy: 0.0111\n",
            "Epoch 3/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0256 - accuracy: 0.0100 - val_loss: 0.0247 - val_accuracy: 0.0084\n",
            "Epoch 4/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0246 - accuracy: 0.0113 - val_loss: 0.0234 - val_accuracy: 0.0132\n",
            "Epoch 5/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0235 - accuracy: 0.0110 - val_loss: 0.0227 - val_accuracy: 0.0140\n",
            "Epoch 6/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0228 - accuracy: 0.0117 - val_loss: 0.0223 - val_accuracy: 0.0131\n",
            "Epoch 7/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0225 - accuracy: 0.0115 - val_loss: 0.0221 - val_accuracy: 0.0122\n",
            "Epoch 8/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0222 - accuracy: 0.0115 - val_loss: 0.0219 - val_accuracy: 0.0117\n",
            "Epoch 9/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0220 - accuracy: 0.0112 - val_loss: 0.0217 - val_accuracy: 0.0109\n",
            "Epoch 10/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0218 - accuracy: 0.0123 - val_loss: 0.0215 - val_accuracy: 0.0124\n",
            "Epoch 11/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0216 - accuracy: 0.0119 - val_loss: 0.0215 - val_accuracy: 0.0135\n",
            "Epoch 12/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0215 - accuracy: 0.0115 - val_loss: 0.0213 - val_accuracy: 0.0110\n",
            "Epoch 13/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.0120 - val_loss: 0.0211 - val_accuracy: 0.0142\n",
            "Epoch 14/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0212 - accuracy: 0.0120 - val_loss: 0.0211 - val_accuracy: 0.0136\n",
            "Epoch 15/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0212 - accuracy: 0.0128 - val_loss: 0.0210 - val_accuracy: 0.0108\n",
            "Epoch 16/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0210 - accuracy: 0.0128 - val_loss: 0.0209 - val_accuracy: 0.0102\n",
            "Epoch 17/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0210 - accuracy: 0.0124 - val_loss: 0.0209 - val_accuracy: 0.0136\n",
            "Epoch 18/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0209 - accuracy: 0.0121 - val_loss: 0.0208 - val_accuracy: 0.0111\n",
            "Epoch 19/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0209 - accuracy: 0.0124 - val_loss: 0.0208 - val_accuracy: 0.0123\n",
            "Epoch 20/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0208 - accuracy: 0.0127 - val_loss: 0.0207 - val_accuracy: 0.0144\n",
            "Epoch 21/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0207 - accuracy: 0.0118 - val_loss: 0.0207 - val_accuracy: 0.0125\n",
            "Epoch 22/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0207 - accuracy: 0.0121 - val_loss: 0.0205 - val_accuracy: 0.0135\n",
            "Epoch 23/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0206 - accuracy: 0.0119 - val_loss: 0.0207 - val_accuracy: 0.0103\n",
            "Epoch 24/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0206 - accuracy: 0.0129 - val_loss: 0.0205 - val_accuracy: 0.0124\n",
            "Epoch 25/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0206 - accuracy: 0.0117 - val_loss: 0.0206 - val_accuracy: 0.0130\n",
            "Epoch 26/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0204 - accuracy: 0.0124 - val_loss: 0.0206 - val_accuracy: 0.0128\n",
            "Epoch 27/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0204 - accuracy: 0.0131 - val_loss: 0.0204 - val_accuracy: 0.0126\n",
            "Epoch 28/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0204 - accuracy: 0.0130 - val_loss: 0.0203 - val_accuracy: 0.0108\n",
            "Epoch 29/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0204 - accuracy: 0.0131 - val_loss: 0.0205 - val_accuracy: 0.0133\n",
            "Epoch 30/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0203 - accuracy: 0.0123 - val_loss: 0.0203 - val_accuracy: 0.0121\n",
            "Epoch 31/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0203 - accuracy: 0.0116 - val_loss: 0.0204 - val_accuracy: 0.0118\n",
            "Epoch 32/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.0116 - val_loss: 0.0202 - val_accuracy: 0.0124\n",
            "Epoch 33/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.0124 - val_loss: 0.0202 - val_accuracy: 0.0151\n",
            "Epoch 34/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.0130 - val_loss: 0.0202 - val_accuracy: 0.0111\n",
            "Epoch 35/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0203 - accuracy: 0.0123 - val_loss: 0.0203 - val_accuracy: 0.0134\n",
            "Epoch 36/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.0119 - val_loss: 0.0203 - val_accuracy: 0.0123\n",
            "Epoch 37/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.0121 - val_loss: 0.0202 - val_accuracy: 0.0110\n",
            "Epoch 38/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.0115 - val_loss: 0.0202 - val_accuracy: 0.0137\n",
            "Epoch 39/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.0118 - val_loss: 0.0201 - val_accuracy: 0.0122\n",
            "Epoch 40/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0201 - accuracy: 0.0113 - val_loss: 0.0201 - val_accuracy: 0.0115\n",
            "Epoch 41/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0201 - accuracy: 0.0123 - val_loss: 0.0202 - val_accuracy: 0.0133\n",
            "Epoch 42/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0201 - accuracy: 0.0123 - val_loss: 0.0201 - val_accuracy: 0.0138\n",
            "Epoch 43/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0201 - accuracy: 0.0119 - val_loss: 0.0201 - val_accuracy: 0.0130\n",
            "Epoch 44/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0201 - accuracy: 0.0126 - val_loss: 0.0200 - val_accuracy: 0.0139\n",
            "Epoch 45/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0200 - accuracy: 0.0125 - val_loss: 0.0201 - val_accuracy: 0.0127\n",
            "Epoch 46/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0200 - accuracy: 0.0129 - val_loss: 0.0201 - val_accuracy: 0.0113\n",
            "Epoch 47/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0201 - accuracy: 0.0130 - val_loss: 0.0201 - val_accuracy: 0.0099\n",
            "Epoch 48/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0131 - val_loss: 0.0200 - val_accuracy: 0.0124\n",
            "Epoch 49/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0200 - accuracy: 0.0118 - val_loss: 0.0200 - val_accuracy: 0.0139\n",
            "Epoch 50/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0200 - accuracy: 0.0119 - val_loss: 0.0200 - val_accuracy: 0.0143\n",
            "Epoch 51/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0120 - val_loss: 0.0199 - val_accuracy: 0.0116\n",
            "Epoch 52/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0118 - val_loss: 0.0199 - val_accuracy: 0.0131\n",
            "Epoch 53/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0127 - val_loss: 0.0201 - val_accuracy: 0.0126\n",
            "Epoch 54/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0124 - val_loss: 0.0200 - val_accuracy: 0.0112\n",
            "Epoch 55/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0129 - val_loss: 0.0200 - val_accuracy: 0.0103\n",
            "Epoch 56/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0120 - val_loss: 0.0200 - val_accuracy: 0.0135\n",
            "Epoch 57/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0120 - val_loss: 0.0201 - val_accuracy: 0.0134\n",
            "Epoch 58/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0124 - val_loss: 0.0200 - val_accuracy: 0.0123\n",
            "Epoch 59/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0118 - val_loss: 0.0200 - val_accuracy: 0.0102\n",
            "Epoch 60/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0199 - accuracy: 0.0115 - val_loss: 0.0200 - val_accuracy: 0.0115\n",
            "Epoch 61/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0118 - val_loss: 0.0200 - val_accuracy: 0.0112\n",
            "Epoch 62/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0133 - val_loss: 0.0200 - val_accuracy: 0.0130\n",
            "Epoch 63/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0120 - val_loss: 0.0199 - val_accuracy: 0.0113\n",
            "Epoch 64/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0128 - val_loss: 0.0200 - val_accuracy: 0.0126\n",
            "Epoch 65/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0125 - val_loss: 0.0200 - val_accuracy: 0.0102\n",
            "Epoch 66/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0116 - val_loss: 0.0199 - val_accuracy: 0.0097\n",
            "Epoch 67/150\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0198 - accuracy: 0.0124 - val_loss: 0.0199 - val_accuracy: 0.0132\n",
            "Epoch 68/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0120 - val_loss: 0.0200 - val_accuracy: 0.0125\n",
            "Epoch 69/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0119 - val_loss: 0.0199 - val_accuracy: 0.0130\n",
            "Epoch 70/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0118 - val_loss: 0.0199 - val_accuracy: 0.0118\n",
            "Epoch 71/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0121 - val_loss: 0.0199 - val_accuracy: 0.0110\n",
            "Epoch 72/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0126 - val_loss: 0.0199 - val_accuracy: 0.0128\n",
            "Epoch 73/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0123 - val_loss: 0.0200 - val_accuracy: 0.0109\n",
            "Epoch 74/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0119 - val_loss: 0.0199 - val_accuracy: 0.0105\n",
            "Epoch 75/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0126 - val_loss: 0.0201 - val_accuracy: 0.0107\n",
            "Epoch 76/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0126 - val_loss: 0.0198 - val_accuracy: 0.0108\n",
            "Epoch 77/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0198 - accuracy: 0.0128 - val_loss: 0.0199 - val_accuracy: 0.0107\n",
            "Epoch 78/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0121 - val_loss: 0.0199 - val_accuracy: 0.0114\n",
            "Epoch 79/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0197 - accuracy: 0.0120 - val_loss: 0.0199 - val_accuracy: 0.0113\n",
            "Epoch 80/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0118 - val_loss: 0.0200 - val_accuracy: 0.0135\n",
            "Epoch 81/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0131 - val_loss: 0.0198 - val_accuracy: 0.0133\n",
            "Epoch 82/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0120 - val_loss: 0.0199 - val_accuracy: 0.0105\n",
            "Epoch 83/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0123 - val_loss: 0.0198 - val_accuracy: 0.0110\n",
            "Epoch 84/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0128 - val_loss: 0.0200 - val_accuracy: 0.0123\n",
            "Epoch 85/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0111 - val_loss: 0.0197 - val_accuracy: 0.0109\n",
            "Epoch 86/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0121 - val_loss: 0.0199 - val_accuracy: 0.0137\n",
            "Epoch 87/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0132 - val_loss: 0.0197 - val_accuracy: 0.0109\n",
            "Epoch 88/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0118 - val_loss: 0.0198 - val_accuracy: 0.0107\n",
            "Epoch 89/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0120 - val_loss: 0.0198 - val_accuracy: 0.0123\n",
            "Epoch 90/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0123 - val_loss: 0.0198 - val_accuracy: 0.0130\n",
            "Epoch 91/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0117 - val_loss: 0.0198 - val_accuracy: 0.0120\n",
            "Epoch 92/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0124 - val_loss: 0.0199 - val_accuracy: 0.0131\n",
            "Epoch 93/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0125 - val_loss: 0.0199 - val_accuracy: 0.0121\n",
            "Epoch 94/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0119 - val_loss: 0.0197 - val_accuracy: 0.0116\n",
            "Epoch 95/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0123 - val_loss: 0.0198 - val_accuracy: 0.0131\n",
            "Epoch 96/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0125 - val_loss: 0.0198 - val_accuracy: 0.0103\n",
            "Epoch 97/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0123 - val_loss: 0.0200 - val_accuracy: 0.0102\n",
            "Epoch 98/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0117 - val_loss: 0.0196 - val_accuracy: 0.0121\n",
            "Epoch 99/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0117 - val_loss: 0.0197 - val_accuracy: 0.0114\n",
            "Epoch 100/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0122 - val_loss: 0.0197 - val_accuracy: 0.0123\n",
            "Epoch 101/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0129 - val_loss: 0.0198 - val_accuracy: 0.0124\n",
            "Epoch 102/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0121 - val_loss: 0.0198 - val_accuracy: 0.0120\n",
            "Epoch 103/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0121 - val_loss: 0.0199 - val_accuracy: 0.0116\n",
            "Epoch 104/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0127 - val_loss: 0.0197 - val_accuracy: 0.0123\n",
            "Epoch 105/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0118 - val_loss: 0.0199 - val_accuracy: 0.0142\n",
            "Epoch 106/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0133 - val_loss: 0.0197 - val_accuracy: 0.0115\n",
            "Epoch 107/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0116 - val_loss: 0.0197 - val_accuracy: 0.0128\n",
            "Epoch 108/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0129 - val_loss: 0.0198 - val_accuracy: 0.0133\n",
            "Epoch 109/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0125 - val_loss: 0.0199 - val_accuracy: 0.0126\n",
            "Epoch 110/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0121 - val_loss: 0.0197 - val_accuracy: 0.0131\n",
            "Epoch 111/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0196 - accuracy: 0.0125 - val_loss: 0.0197 - val_accuracy: 0.0122\n",
            "Epoch 112/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0122 - val_loss: 0.0198 - val_accuracy: 0.0135\n",
            "Epoch 113/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0123 - val_loss: 0.0198 - val_accuracy: 0.0124\n",
            "Epoch 114/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0128 - val_loss: 0.0197 - val_accuracy: 0.0157\n",
            "Epoch 115/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0112 - val_loss: 0.0197 - val_accuracy: 0.0130\n",
            "Epoch 116/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0121 - val_loss: 0.0197 - val_accuracy: 0.0097\n",
            "Epoch 117/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0127 - val_loss: 0.0197 - val_accuracy: 0.0116\n",
            "Epoch 118/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0117 - val_loss: 0.0196 - val_accuracy: 0.0119\n",
            "Epoch 119/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0128 - val_loss: 0.0197 - val_accuracy: 0.0117\n",
            "Epoch 120/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0123 - val_loss: 0.0196 - val_accuracy: 0.0145\n",
            "Epoch 121/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0125 - val_loss: 0.0198 - val_accuracy: 0.0113\n",
            "Epoch 122/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0127 - val_loss: 0.0197 - val_accuracy: 0.0120\n",
            "Epoch 123/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0118 - val_loss: 0.0197 - val_accuracy: 0.0128\n",
            "Epoch 124/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0123 - val_loss: 0.0198 - val_accuracy: 0.0105\n",
            "Epoch 125/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0119 - val_loss: 0.0197 - val_accuracy: 0.0129\n",
            "Epoch 126/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - accuracy: 0.0115 - val_loss: 0.0196 - val_accuracy: 0.0113\n",
            "Epoch 127/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0124 - val_loss: 0.0198 - val_accuracy: 0.0118\n",
            "Epoch 128/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0126 - val_loss: 0.0196 - val_accuracy: 0.0124\n",
            "Epoch 129/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0132 - val_loss: 0.0196 - val_accuracy: 0.0119\n",
            "Epoch 130/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0119 - val_loss: 0.0197 - val_accuracy: 0.0117\n",
            "Epoch 131/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0132 - val_loss: 0.0197 - val_accuracy: 0.0137\n",
            "Epoch 132/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0135 - val_loss: 0.0197 - val_accuracy: 0.0130\n",
            "Epoch 133/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193 - accuracy: 0.0118 - val_loss: 0.0196 - val_accuracy: 0.0127\n",
            "Epoch 134/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0112 - val_loss: 0.0198 - val_accuracy: 0.0121\n",
            "Epoch 135/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0127 - val_loss: 0.0197 - val_accuracy: 0.0131\n",
            "Epoch 136/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0126 - val_loss: 0.0197 - val_accuracy: 0.0121\n",
            "Epoch 137/150\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0194 - accuracy: 0.0123 - val_loss: 0.0198 - val_accuracy: 0.0112\n",
            "Epoch 138/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0118 - val_loss: 0.0196 - val_accuracy: 0.0132\n",
            "Epoch 139/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0135 - val_loss: 0.0196 - val_accuracy: 0.0106\n",
            "Epoch 140/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193 - accuracy: 0.0125 - val_loss: 0.0198 - val_accuracy: 0.0136\n",
            "Epoch 141/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193 - accuracy: 0.0115 - val_loss: 0.0196 - val_accuracy: 0.0148\n",
            "Epoch 142/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0123 - val_loss: 0.0197 - val_accuracy: 0.0106\n",
            "Epoch 143/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0115 - val_loss: 0.0198 - val_accuracy: 0.0132\n",
            "Epoch 144/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0128 - val_loss: 0.0197 - val_accuracy: 0.0127\n",
            "Epoch 145/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193 - accuracy: 0.0119 - val_loss: 0.0196 - val_accuracy: 0.0135\n",
            "Epoch 146/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193 - accuracy: 0.0115 - val_loss: 0.0197 - val_accuracy: 0.0118\n",
            "Epoch 147/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0116 - val_loss: 0.0196 - val_accuracy: 0.0140\n",
            "Epoch 148/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0126 - val_loss: 0.0198 - val_accuracy: 0.0147\n",
            "Epoch 149/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0125 - val_loss: 0.0196 - val_accuracy: 0.0109\n",
            "Epoch 150/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0194 - accuracy: 0.0125 - val_loss: 0.0197 - val_accuracy: 0.0136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEAV2ZNVSKTD"
      },
      "source": [
        "sample1 = X_train[0].reshape(28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "eGEMSzQXSdgS",
        "outputId": "f8c9c7ae-bcbd-4d6f-bcd2-a6dbbfd7ec64"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(sample1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6dd0296190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTvgbd8TSjVJ"
      },
      "source": [
        "decoderop_sample1 = model.predict(X_train[0].reshape(1,-1)).reshape(28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Z36Twf2IS23S",
        "outputId": "808d2d19-0a02-4c31-c0a6-7767784c4329"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(decoderop_sample1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6dd02ff2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_orBM95T3N_",
        "outputId": "3792c67a-bdfe-4e76-9f2d-bbc387d1bcf6"
      },
      "source": [
        "#autoencoder 1\n",
        "input_img = Input(shape=(784,))\n",
        "en1 = Dense(200,activation='relu')(input_img)\n",
        "code1 = Dense(100,activation='relu')(en1)\n",
        "de1 = Dense(200,activation='relu')(code1)\n",
        "output1 = Dense(784,activation='relu')(de1)\n",
        "\n",
        "model1 = Model(inputs=input_img,outputs=output1)\n",
        "model1.compile(optimizer='adam',loss='mse')\n",
        "history1 = model1.fit(X_train,X_train,epochs=150,batch_size=32,validation_data=(X_test,X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0237 - val_loss: 0.0101\n",
            "Epoch 2/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0100 - val_loss: 0.0089\n",
            "Epoch 3/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0090 - val_loss: 0.0085\n",
            "Epoch 4/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0087 - val_loss: 0.0083\n",
            "Epoch 5/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0085 - val_loss: 0.0082\n",
            "Epoch 6/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0083 - val_loss: 0.0082\n",
            "Epoch 7/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0083 - val_loss: 0.0080\n",
            "Epoch 8/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0082 - val_loss: 0.0080\n",
            "Epoch 9/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0082 - val_loss: 0.0079\n",
            "Epoch 10/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0081 - val_loss: 0.0079\n",
            "Epoch 11/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0081 - val_loss: 0.0078\n",
            "Epoch 12/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0080 - val_loss: 0.0078\n",
            "Epoch 13/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 14/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0079 - val_loss: 0.0077\n",
            "Epoch 15/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0079 - val_loss: 0.0077\n",
            "Epoch 16/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 17/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0078 - val_loss: 0.0076\n",
            "Epoch 18/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0078 - val_loss: 0.0076\n",
            "Epoch 19/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0078 - val_loss: 0.0075\n",
            "Epoch 20/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0078 - val_loss: 0.0076\n",
            "Epoch 21/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0077 - val_loss: 0.0077\n",
            "Epoch 22/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
            "Epoch 23/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
            "Epoch 24/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0076 - val_loss: 0.0075\n",
            "Epoch 25/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
            "Epoch 26/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 27/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 28/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 29/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 30/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 31/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0075 - val_loss: 0.0072\n",
            "Epoch 32/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
            "Epoch 33/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 34/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 35/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 36/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 37/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 38/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 39/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
            "Epoch 40/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 41/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0071 - val_loss: 0.0071\n",
            "Epoch 42/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 43/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
            "Epoch 44/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
            "Epoch 45/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0071 - val_loss: 0.0070\n",
            "Epoch 46/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0070 - val_loss: 0.0069\n",
            "Epoch 47/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0070 - val_loss: 0.0069\n",
            "Epoch 48/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 49/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 50/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 51/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 52/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 53/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - val_loss: 0.0069\n",
            "Epoch 54/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 55/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0069 - val_loss: 0.0069\n",
            "Epoch 56/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0070 - val_loss: 0.0067\n",
            "Epoch 57/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 58/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 59/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 60/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 61/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 62/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0069\n",
            "Epoch 63/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 64/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068 - val_loss: 0.0068\n",
            "Epoch 65/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 66/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 67/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 68/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0068\n",
            "Epoch 69/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 70/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 71/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 72/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 73/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 74/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 75/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 76/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 77/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 78/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 79/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 80/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068 - val_loss: 0.0065\n",
            "Epoch 81/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 82/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 83/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 84/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 85/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 86/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 87/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 88/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 89/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 90/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 91/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 92/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 93/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 94/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 95/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 96/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 97/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 98/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 99/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 100/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 101/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 102/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 103/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 104/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 105/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 106/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 107/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 108/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 109/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 110/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 111/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 112/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 113/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 114/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 115/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 116/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 117/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 118/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 119/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 120/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 121/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 122/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 123/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 124/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 125/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 126/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 127/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 128/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 129/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 130/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 131/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 132/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 133/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 134/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 135/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 136/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 137/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 138/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 139/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 140/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 141/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 142/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 143/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 144/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 145/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 146/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 147/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 148/150\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 149/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0065 - val_loss: 0.0064\n",
            "Epoch 150/150\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zARN4boGYVD7",
        "outputId": "b23e4957-063c-4180-bdf7-e798a57063a9"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 784)               157584    \n",
            "=================================================================\n",
            "Total params: 354,884\n",
            "Trainable params: 354,884\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QObXtDqxW7o_"
      },
      "source": [
        "intermediate_layer_model = Model(inputs=model1.input, \n",
        "                                 outputs=model1.get_layer(\"dense_5\").output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drmBfPiyZIzs"
      },
      "source": [
        "code1_train = intermediate_layer_model.predict(X_train)\n",
        "code1_test = intermediate_layer_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4MHxM6iVoiW",
        "outputId": "bdd77fe3-aa7f-4ba8-fa49-d33baf1fde69"
      },
      "source": [
        "#autoencoder 1\n",
        "input_img2 = Input(shape=(100,))\n",
        "en2 = Dense(50,activation='relu')(input_img2)\n",
        "output2 = Dense(100,activation='relu')(en2)\n",
        "\n",
        "model2 = Model(inputs=input_img2,outputs=output2)\n",
        "model2.summary()\n",
        "model2.compile(optimizer='adam',loss='mse')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               5100      \n",
            "=================================================================\n",
            "Total params: 10,150\n",
            "Trainable params: 10,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj6zVx9CblUM",
        "outputId": "a4fb2de8-cabd-4144-dc64-c48c15439952"
      },
      "source": [
        "history2 = model2.fit(code1_train,code1_train,epochs=50,batch_size=32,validation_data=(code1_test,code1_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1907 - val_loss: 0.0840\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0839 - val_loss: 0.0780\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0795 - val_loss: 0.0769\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0788 - val_loss: 0.0753\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0768 - val_loss: 0.0738\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0752 - val_loss: 0.0736\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0750 - val_loss: 0.0732\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0749 - val_loss: 0.0732\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0747 - val_loss: 0.0733\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0748 - val_loss: 0.0734\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0749 - val_loss: 0.0731\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0747 - val_loss: 0.0734\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0749 - val_loss: 0.0732\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0747 - val_loss: 0.0730\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0747 - val_loss: 0.0731\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0745 - val_loss: 0.0729\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0746 - val_loss: 0.0730\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0743 - val_loss: 0.0730\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0745 - val_loss: 0.0731\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0744 - val_loss: 0.0729\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0745 - val_loss: 0.0728\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0747 - val_loss: 0.0729\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0743 - val_loss: 0.0729\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0745 - val_loss: 0.0728\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0728\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0744 - val_loss: 0.0728\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0743 - val_loss: 0.0729\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0728\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0729\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0727\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0729\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0743 - val_loss: 0.0728\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0743 - val_loss: 0.0727\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0744 - val_loss: 0.0727\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0741 - val_loss: 0.0728\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0729\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0726\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0744 - val_loss: 0.0727\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0741 - val_loss: 0.0728\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0743 - val_loss: 0.0728\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0743 - val_loss: 0.0727\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0744 - val_loss: 0.0729\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0744 - val_loss: 0.0727\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0740 - val_loss: 0.0727\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0726\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0743 - val_loss: 0.0727\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0742 - val_loss: 0.0727\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0743 - val_loss: 0.0727\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0739 - val_loss: 0.0727\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0742 - val_loss: 0.0727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHhgeFHpcgkl"
      },
      "source": [
        "intermediate_layer_model2 = Model(inputs=model2.input, \n",
        "                                 outputs=model2.get_layer(\"dense_8\").output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXM0_6QrHbEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b3eb1a-b9c4-4f09-8c4d-23fc2bd1c28d"
      },
      "source": [
        "intermediate_layer_model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                5050      \n",
            "=================================================================\n",
            "Total params: 5,050\n",
            "Trainable params: 5,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCIG98Raco_R"
      },
      "source": [
        "code2_train = intermediate_layer_model2.predict(code1_train)\n",
        "code2_test = intermediate_layer_model2.predict(code1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52VXee9BcxLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f404d0-9b2d-464a-97f6-dee6bb8909e3"
      },
      "source": [
        "code2_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1t2B4rbb2Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ba0ab5-0252-43b6-9072-81129a515956"
      },
      "source": [
        "#autoencoder 1\n",
        "input_img3 = Input(shape=(50,))\n",
        "en3 = Dense(30,activation='relu')(input_img3)\n",
        "output3 = Dense(50,activation='relu')(en3)\n",
        "\n",
        "model3 = Model(inputs=input_img3,outputs=output3)\n",
        "model3.summary()\n",
        "model3.compile(optimizer='adam',loss='mse')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 30)                1530      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 50)                1550      \n",
            "=================================================================\n",
            "Total params: 3,080\n",
            "Trainable params: 3,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkB1qyq8ccbk",
        "outputId": "8a0d6550-5afb-486b-8ef3-3b1e54a1c9eb"
      },
      "source": [
        "history3 = model3.fit(code2_train,code2_train,epochs=100,batch_size=32,validation_data=(code2_test,code2_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0492 - val_loss: 0.0092\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0082\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0084 - val_loss: 0.0080\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0078 - val_loss: 0.0072\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0073 - val_loss: 0.0071\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0073 - val_loss: 0.0071\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0073 - val_loss: 0.0070\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njIl15i_fCPW"
      },
      "source": [
        "decoder_input1 = Input(shape = (100,))\n",
        "next_layer = decoder_input1\n",
        "for layer in model1.layers[-2:]:\n",
        "    next_layer = layer(next_layer)\n",
        " \n",
        "decoder1 = Model(decoder_input1, next_layer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBo2fh5wgOQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e67388-c973-4673-8c9f-4bf3d745ccf9"
      },
      "source": [
        "decoder1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 784)               157584    \n",
            "=================================================================\n",
            "Total params: 177,784\n",
            "Trainable params: 177,784\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l-zRbGng-v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6b4b7b-0c24-4962-b333-dfa06f93e822"
      },
      "source": [
        "decoder_input2 = Input(shape = (50,))\n",
        "next_layer2 = decoder_input2\n",
        "for layer in model2.layers[-1:]:\n",
        "    next_layer2 = layer(next_layer2)\n",
        " \n",
        "decoder2 = Model(decoder_input2, next_layer2)\n",
        "decoder2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               5100      \n",
            "=================================================================\n",
            "Total params: 5,100\n",
            "Trainable params: 5,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p76FqbmLdmq0"
      },
      "source": [
        "sample = X_train[0].reshape(1,-1)\n",
        "sample = intermediate_layer_model.predict(sample)#100\n",
        "sample = intermediate_layer_model2.predict(sample)#50\n",
        "sample = model3.predict(sample)#50\n",
        "sample = decoder2.predict(sample)\n",
        "sample = decoder1.predict(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkXxpR2IheWI"
      },
      "source": [
        "sample = sample.reshape(28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Vv47Odhppz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "68603079-7877-4622-d95d-883d4d941ff0"
      },
      "source": [
        "plt.imshow(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6d88185290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K6HpmodI6pK"
      },
      "source": [
        "intermediate_layer_model3 = Model(inputs=model3.input, \n",
        "                                 outputs=model3.get_layer(\"dense_10\").output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmb0YpqoJEi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1b8c4e-f4fc-4748-9a6a-070e5dca1c87"
      },
      "source": [
        "intermediate_layer_model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 30)                1530      \n",
            "=================================================================\n",
            "Total params: 1,530\n",
            "Trainable params: 1,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-pf2FmOJJa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df60dba0-e3a2-430f-fb21-cc83e3ee71e6"
      },
      "source": [
        "latent_code_train = intermediate_layer_model3.predict(code2_train)\n",
        "latent_code_test = intermediate_layer_model3.predict(code2_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 319 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6d981a9a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyOG9_pKJfu7"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=3, random_state=0).fit(latent_code_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ3vfZwIKa3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7b02f6-4293-474c-a3b2-5d96d8d25b58"
      },
      "source": [
        "clf.score(latent_code_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcuHbQFGpD9n",
        "outputId": "0c9e1fd8-dac4-4a71-8916-865bef71aefa"
      },
      "source": [
        "intermediate_layer_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               20100     \n",
            "=================================================================\n",
            "Total params: 177,100\n",
            "Trainable params: 177,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmN9vxxomyp0"
      },
      "source": [
        "fine_tuning = Sequential()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9h4mmVbo9zu"
      },
      "source": [
        "fine_tuning.add(intermediate_layer_model)\n",
        "for i in intermediate_layer_model2.layers[1:]:\n",
        "  fine_tuning.add(i)\n",
        "for i in intermediate_layer_model3.layers[1:]:\n",
        "  fine_tuning.add(i)\n",
        "fine_tuning.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWlU_oeWqFBR",
        "outputId": "6fdc07e8-a51d-44c7-de34-c793ad82fe14"
      },
      "source": [
        "fine_tuning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Functional)         (None, 100)               177100    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 30)                1530      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 183,990\n",
            "Trainable params: 183,990\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mAGNq_9qLnl"
      },
      "source": [
        "fine_tuning.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvtJf043qnFf"
      },
      "source": [
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31kGV4vprBsS",
        "outputId": "ae8e0b35-ad44-44ca-a9dd-8e0562ba6292"
      },
      "source": [
        "y_train_cat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ngcri7PqW2h",
        "outputId": "8c38e7ce-c5bd-4ec1-84e6-59b756a1ed4f"
      },
      "source": [
        "fine_tuning.fit(X_train,y_train_cat,epochs=50,batch_size=32,validation_data=(X_test,y_test_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5072 - accuracy: 0.8431 - val_loss: 0.1254 - val_accuracy: 0.9618\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1042 - accuracy: 0.9685 - val_loss: 0.0961 - val_accuracy: 0.9714\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0692 - accuracy: 0.9787 - val_loss: 0.0800 - val_accuracy: 0.9762\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0483 - accuracy: 0.9845 - val_loss: 0.0816 - val_accuracy: 0.9761\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0372 - accuracy: 0.9879 - val_loss: 0.0849 - val_accuracy: 0.9772\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0885 - val_accuracy: 0.9764\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.0835 - val_accuracy: 0.9791\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0962 - val_accuracy: 0.9767\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0788 - val_accuracy: 0.9807\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.1052 - val_accuracy: 0.9760\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1063 - val_accuracy: 0.9748\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0976 - val_accuracy: 0.9781\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0938 - val_accuracy: 0.9796\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.1164 - val_accuracy: 0.9789\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0966 - val_accuracy: 0.9805\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.1212 - val_accuracy: 0.9773\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0929 - val_accuracy: 0.9817\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.1123 - val_accuracy: 0.9796\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0894 - val_accuracy: 0.9816\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0903 - val_accuracy: 0.9831\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1120 - val_accuracy: 0.9806\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0932 - val_accuracy: 0.9817\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1155 - val_accuracy: 0.9788\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1006 - val_accuracy: 0.9805\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1146 - val_accuracy: 0.9806\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.1322 - val_accuracy: 0.9774\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.1200 - val_accuracy: 0.9816\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1358 - val_accuracy: 0.9791\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1179 - val_accuracy: 0.9820\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1257 - val_accuracy: 0.9818\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1153 - val_accuracy: 0.9816\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1391 - val_accuracy: 0.9824\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.1407 - val_accuracy: 0.9802\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.1476 - val_accuracy: 0.9799\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.1150 - val_accuracy: 0.9828\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1181 - val_accuracy: 0.9819\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1204 - val_accuracy: 0.9813\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1198 - val_accuracy: 0.9804\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1285 - val_accuracy: 0.9829\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1516 - val_accuracy: 0.9802\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1558 - val_accuracy: 0.9789\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1340 - val_accuracy: 0.9817\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1385 - val_accuracy: 0.9814\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.1305 - val_accuracy: 0.9816\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1520 - val_accuracy: 0.9800\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1431 - val_accuracy: 0.9818\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1685 - val_accuracy: 0.9777\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.1419 - val_accuracy: 0.9810\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1469 - val_accuracy: 0.9838\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1394 - val_accuracy: 0.9840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6d6531d090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}